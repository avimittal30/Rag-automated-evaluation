{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f1dac85df23c419cb431b768b445b96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c111da38c52546489a0f334123e28714",
              "IPY_MODEL_45811aeed8f243478d479f43ded013ac",
              "IPY_MODEL_2e145e34a07f4c25bba5d4e8e1e6c797"
            ],
            "layout": "IPY_MODEL_8b077dee05f4498ea56bcd636cca71f1"
          }
        },
        "c111da38c52546489a0f334123e28714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1237649f66c450ab9517a2c309e8fc5",
            "placeholder": "​",
            "style": "IPY_MODEL_1876d13a3337443fb14f7a8de3a2ac0c",
            "value": "Testing Configurations: 100%"
          }
        },
        "45811aeed8f243478d479f43ded013ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77949978ca184281bbe71511bec0eefe",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b218901e46634732b8e83f8437d1e680",
            "value": 8
          }
        },
        "2e145e34a07f4c25bba5d4e8e1e6c797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e7eb82dc3447b9849475e2f79928d6",
            "placeholder": "​",
            "style": "IPY_MODEL_9c5f585e61c5408b92968e63bc8de7aa",
            "value": " 8/8 [04:03&lt;00:00, 30.81s/it]"
          }
        },
        "8b077dee05f4498ea56bcd636cca71f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1237649f66c450ab9517a2c309e8fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1876d13a3337443fb14f7a8de3a2ac0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77949978ca184281bbe71511bec0eefe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b218901e46634732b8e83f8437d1e680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02e7eb82dc3447b9849475e2f79928d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c5f585e61c5408b92968e63bc8de7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9vNU6nygcAI",
        "outputId": "f84eac79-9e2c-40c2-e2f5-df894a0a3e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.14)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0 jedi-0.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai pandas numpy faiss-cpu ipywidgets tqdm scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os                     # For accessing environment variables (like API keys)\n",
        "import time                   # For timing operations\n",
        "import re                     # For regular expressions (text cleaning)\n",
        "import warnings               # For controlling warning messages\n",
        "import itertools              # For creating parameter combinations easily\n",
        "import getpass                # For securely prompting for API keys if not set\n",
        "\n",
        "import numpy as np            # Numerical library for vector operations\n",
        "import pandas as pd           # Data manipulation library for tables (DataFrames)\n",
        "import faiss                  # Library for fast vector similarity search\n",
        "from openai import OpenAI     # Client library for Nebius API interaction\n",
        "from tqdm.notebook import tqdm # Library for displaying progress bars\n",
        "from sklearn.metrics.pairwise import cosine_similarity # For calculating similarity score\n",
        "\n",
        "# Configure display options for Pandas DataFrames for better readability\n",
        "pd.set_option('display.max_colwidth', 150) # Show more text content in table cells\n",
        "pd.set_option('display.max_rows', 100)     # Display more rows in tables\n",
        "warnings.filterwarnings('ignore', category=FutureWarning) # Suppress specific non-critical warnings\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csbf9lASgefi",
        "outputId": "b3dcd12d-f6ac-431d-a8b3-d4d4a679887c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY']= userdata.get('OPENAI_API_KEY')\n",
        "api_key=userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "xgLybeoUgte2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If using a local model like Ollama\n",
        "OPENAI_API_KEY='ollama' # Can be any non-empty string for Ollama\n",
        "OPENAI_API_BASE='http://localhost:11434/v1'\n",
        "\n",
        "# --- NebiusAI API Configuration ---\n",
        "# BEST PRACTICE: Use environment variables or a secure method for API keys!\n",
        "NEBIUS_API_KEY = userdata.get('nebius_api_key') # <-- *** SET YOUR KEY SAFELY ***\n",
        "\n",
        "NEBIUS_BASE_URL = \"https://api.studio.nebius.com/v1/\"\n",
        "NEBIUS_EMBEDDING_MODEL = \"BAAI/bge-multilingual-gemma2\"  # For text-to-vector conversion\n",
        "NEBIUS_GENERATION_MODEL = \"deepseek-ai/DeepSeek-V3\"    # For generating final answers\n",
        "NEBIUS_EVALUATION_MODEL = \"deepseek-ai/DeepSeek-V3\"    # For evaluating the generated answers\n",
        "\n",
        "# --- Text Generation Parameters (for the final answer) ---\n",
        "GENERATION_TEMPERATURE = 0.1  # Low temp for factual, focused answers\n",
        "GENERATION_MAX_TOKENS = 400   # Max answer length\n",
        "GENERATION_TOP_P = 0.9        # Usually fine at default\n",
        "\n",
        "# Create the OpenAI client object, configured for the Nebius API.\n",
        "client = OpenAI(\n",
        "    api_key=NEBIUS_API_KEY,     # Pass the API key loaded earlier\n",
        "    base_url=NEBIUS_BASE_URL  # Specify the Nebius API endpoint\n",
        ")"
      ],
      "metadata": {
        "id": "OYWVTGcxghmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHUNK_SIZES_TO_TEST = [150, 250]    # List of chunk sizes (in words) to experiment with.\n",
        "CHUNK_OVERLAPS_TO_TEST = [30, 50]   # List of chunk overlaps (in words) to experiment with.\n",
        "RETRIEVAL_TOP_K_TO_TEST = [3, 5]   # List of 'k' values (number of chunks to retrieve) to test.\n",
        "\n",
        "# --- Reranking Configuration ---\n",
        "# For simulated reranking: retrieve K * multiplier chunks initially.\n",
        "# A real reranker would then re-score these based on relevance.\n",
        "RERANK_RETRIEVAL_MULTIPLIER = 3"
      ],
      "metadata": {
        "id": "NqWIHm8Qgouo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FAITHFULNESS_PROMPT = \"\"\"\n",
        "System: You are an objective evaluator. Evaluate the faithfulness of the AI Response compared to the True Answer, considering only the information present in the True Answer as the ground truth.\n",
        "Faithfulness measures how accurately the AI response reflects the information in the True Answer, without adding unsupported facts or contradicting it.\n",
        "Score STRICTLY using a float between 0.0 and 1.0, based on this scale:\n",
        "- 0.0: Completely unfaithful, contradicts or fabricates information.\n",
        "- 0.1-0.4: Low faithfulness with significant inaccuracies or unsupported claims.\n",
        "- 0.5-0.6: Partially faithful but with noticeable inaccuracies or omissions.\n",
        "- 0.7-0.8: Mostly faithful with only minor inaccuracies or phrasing differences.\n",
        "- 0.9: Very faithful, slight wording differences but semantically aligned.\n",
        "- 1.0: Completely faithful, accurately reflects the True Answer.\n",
        "Respond ONLY with the numerical score.\n",
        "\n",
        "User:\n",
        "Query: {question}\n",
        "AI Response: {response}\n",
        "True Answer: {true_answer}\n",
        "Score:\"\"\""
      ],
      "metadata": {
        "id": "kzBRYED2hV3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RELEVANCY_PROMPT = \"\"\"\n",
        "System: You are an objective evaluator. Evaluate the relevance of the AI Response to the specific User Query.\n",
        "Relevancy measures how well the response directly answers the user's question, avoiding unnecessary or off-topic information.\n",
        "Score STRICTLY using a float between 0.0 and 1.0, based on this scale:\n",
        "- 0.0: Not relevant at all.\n",
        "- 0.1-0.4: Low relevance, addresses a different topic or misses the core question.\n",
        "- 0.5-0.6: Partially relevant, answers only a part of the query or is tangentially related.\n",
        "- 0.7-0.8: Mostly relevant, addresses the main aspects of the query but might include minor irrelevant details.\n",
        "- 0.9: Highly relevant, directly answers the query with minimal extra information.\n",
        "- 1.0: Completely relevant, directly and fully answers the exact question asked.\n",
        "Respond ONLY with the numerical score.\n",
        "\n",
        "User:\n",
        "Query: {question}\n",
        "AI Response: {response}\n",
        "Score:\"\"\""
      ],
      "metadata": {
        "id": "hfcawaNciYh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our knowledge base: A list of text documents about renewable energy\n",
        "corpus_texts = [\n",
        "    \"Solar power uses PV panels or CSP systems. PV converts sunlight directly to electricity. CSP uses mirrors to heat fluid driving a turbine. It's clean but varies with weather/time. Storage (batteries) is key for consistency.\", # Doc 0\n",
        "    \"Wind energy uses turbines in wind farms. It's sustainable with low operating costs. Wind speed varies, siting can be challenging (visual/noise). Offshore wind is stronger and more consistent.\", # Doc 1\n",
        "    \"Hydropower uses moving water, often via dams spinning turbines. Reliable, large-scale power with flood control/water storage benefits. Big dams harm ecosystems and displace communities. Run-of-river is smaller, less disruptive.\", # Doc 2\n",
        "    \"Geothermal energy uses Earth's heat via steam/hot water for turbines. Consistent 24/7 power, small footprint. High initial drilling costs, sites are geographically limited.\", # Doc 3\n",
        "    \"Biomass energy from organic matter (wood, crops, waste). Burned directly or converted to biofuels. Uses waste, provides dispatchable power. Requires sustainable sourcing. Combustion releases emissions (carbon-neutral if balanced by regrowth).\" # Doc 4\n",
        "]\n",
        "\n",
        "# The question we will ask the RAG system\n",
        "test_query = \"Compare the consistency and environmental impact of solar power versus hydropower.\"\n",
        "\n",
        "# --- The Ground Truth Answer (Derived ONLY from corpus_texts) ---\n",
        "# !!! This is VITAL for reliable evaluation !!!\n",
        "true_answer_for_query = \"Solar power's consistency varies with weather and time of day, requiring storage like batteries. Hydropower is generally reliable, but large dams have significant environmental impacts on ecosystems and communities, unlike solar power's primary impact being land use for panels.\""
      ],
      "metadata": {
        "id": "YoThbOrDiblw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size, chunk_overlap):\n",
        "    \"\"\"Splits a single text document into overlapping chunks based on word count.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to be chunked.\n",
        "        chunk_size (int): The target number of words per chunk.\n",
        "        chunk_overlap (int): The number of words to overlap between consecutive chunks.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of text chunks.\n",
        "    \"\"\"\n",
        "    words = text.split()      # Split the text into a list of individual words\n",
        "    total_words = len(words) # Calculate the total number of words in the text\n",
        "    chunks = []             # Initialize an empty list to store the generated chunks\n",
        "    start_index = 0         # Initialize the starting word index for the first chunk\n",
        "\n",
        "    # --- Input Validation ---\n",
        "    # Ensure chunk_size is a positive integer.\n",
        "    if not isinstance(chunk_size, int) or chunk_size <= 0:\n",
        "        print(f\"  Warning: Invalid chunk_size ({chunk_size}). Must be a positive integer. Returning the whole text as one chunk.\")\n",
        "        return [text]\n",
        "    # Ensure chunk_overlap is a non-negative integer smaller than chunk_size.\n",
        "    if not isinstance(chunk_overlap, int) or chunk_overlap < 0:\n",
        "        print(f\"  Warning: Invalid chunk_overlap ({chunk_overlap}). Must be a non-negative integer. Setting overlap to 0.\")\n",
        "        chunk_overlap = 0\n",
        "    if chunk_overlap >= chunk_size:\n",
        "        # If overlap is too large, adjust it to a reasonable fraction (e.g., 1/3) of chunk_size\n",
        "        # This prevents infinite loops or nonsensical chunking.\n",
        "        adjusted_overlap = chunk_size // 3\n",
        "        print(f\"  Warning: chunk_overlap ({chunk_overlap}) >= chunk_size ({chunk_size}). Adjusting overlap to {adjusted_overlap}.\")\n",
        "        chunk_overlap = adjusted_overlap\n",
        "\n",
        "    # --- Chunking Loop ---\n",
        "    # Continue chunking as long as the start_index is within the bounds of the text\n",
        "    while start_index < total_words:\n",
        "        # Determine the end index for the current chunk.\n",
        "        # It's the minimum of (start + chunk_size) and the total number of words.\n",
        "        end_index = min(start_index + chunk_size, total_words)\n",
        "\n",
        "        # Extract the words for the current chunk and join them back into a single string.\n",
        "        current_chunk_text = \" \".join(words[start_index:end_index])\n",
        "        chunks.append(current_chunk_text) # Add the generated chunk to the list\n",
        "\n",
        "        # Calculate the starting index for the *next* chunk.\n",
        "        # Move forward by (chunk_size - chunk_overlap) words.\n",
        "        next_start_index = start_index + chunk_size - chunk_overlap\n",
        "\n",
        "        # --- Safety Checks ---\n",
        "        # Check 1: Prevent infinite loops if overlap causes no progress.\n",
        "        # This can happen if chunk_size is very small or overlap is very large relative to chunk_size.\n",
        "        if next_start_index <= start_index:\n",
        "            if end_index == total_words: # If we are already at the end, we can safely break.\n",
        "                break\n",
        "            else:\n",
        "                # Force progress by moving forward by at least one word.\n",
        "                print(f\"  Warning: Chunking logic stuck (start={start_index}, next_start={next_start_index}). Forcing progress.\")\n",
        "                next_start_index = start_index + 1\n",
        "\n",
        "        # Check 2: If the calculated next start index is already at or beyond the total number of words, we are done.\n",
        "        if next_start_index >= total_words:\n",
        "            break\n",
        "\n",
        "        # Move the start_index to the calculated position for the next iteration.\n",
        "        start_index = next_start_index\n",
        "\n",
        "    return chunks # Return the complete list of text chunks\n",
        "\n",
        "# --- Quick Test ---\n",
        "# Test the function with the first document and sample parameters.\n",
        "print(\"Defining the 'chunk_text' function.\")\n",
        "sample_chunk_size = 150\n",
        "sample_overlap = 30\n",
        "sample_chunks = chunk_text(corpus_texts[0], sample_chunk_size, sample_overlap)\n",
        "print(f\"Test chunking on first doc (size={sample_chunk_size} words, overlap={sample_overlap} words): Created {len(sample_chunks)} chunks.\")\n",
        "if sample_chunks: # Only print if chunks were created\n",
        "    print(f\"First sample chunk:\\n'{sample_chunks[0]}'\")\n",
        "print(\"-\" * 25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v74eGWgSitHT",
        "outputId": "8289a781-219e-4290-8424-fcd0f68c8b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defining the 'chunk_text' function.\n",
            "Test chunking on first doc (size=150 words, overlap=30 words): Created 1 chunks.\n",
            "First sample chunk:\n",
            "'Solar power uses PV panels or CSP systems. PV converts sunlight directly to electricity. CSP uses mirrors to heat fluid driving a turbine. It's clean but varies with weather/time. Storage (batteries) is key for consistency.'\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Quick Test ---\n",
        "sample_chunk_size = 20\n",
        "sample_overlap = 30\n",
        "# Test with the first document from our corpus\n",
        "sample_chunks = chunk_text(corpus_texts[0], sample_chunk_size, sample_overlap)\n",
        "print(f\"Test chunking on first doc (size={sample_chunk_size}, overlap={sample_overlap}): Created {len(sample_chunks)} chunks.\")\n",
        "if sample_chunks: # Print the first chunk if any were created\n",
        "    print(f\"First sample chunk:\\n'{sample_chunks[0]}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoaRGFOPk1Cx",
        "outputId": "0393f466-9af2-479f-9036-ced336ba8392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Warning: overlap (30) >= size (20). Adjusting to 6.\n",
            "Test chunking on first doc (size=20, overlap=30): Created 3 chunks.\n",
            "First sample chunk:\n",
            "'Solar power uses PV panels or CSP systems. PV converts sunlight directly to electricity. CSP uses mirrors to heat fluid'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = None # Initialize client variable to None globally\n",
        "\n",
        "print(\"Attempting to initialize the Nebius AI client...\")\n",
        "try:\n",
        "    # Check if the API key is actually available before creating the client\n",
        "    if not NEBIUS_API_KEY:\n",
        "        raise ValueError(\"Nebius API Key is missing. Cannot initialize client.\")\n",
        "\n",
        "    # Create the OpenAI client object, configured for the Nebius API.\n",
        "    client = OpenAI(\n",
        "        api_key=NEBIUS_API_KEY,     # Pass the API key loaded earlier\n",
        "        base_url=NEBIUS_BASE_URL  # Specify the Nebius API endpoint\n",
        "    )\n",
        "\n",
        "    # Optional: Add a quick test call to verify the client connection,\n",
        "    # e.g., listing models (if supported and desired). This might incur costs.\n",
        "    # try:\n",
        "    #     client.models.list()\n",
        "    #     print(\"Client connection verified by listing models.\")\n",
        "    # except Exception as test_e:\n",
        "    #     print(f\"Warning: Could not verify client connection with test call: {test_e}\")\n",
        "\n",
        "    print(\"Nebius AI client initialized successfully. Ready to make API calls.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Catch any errors during client initialization (e.g., invalid key, network issues)\n",
        "    print(f\"Error initializing Nebius AI client: {e}\")\n",
        "    print(\"!!! Execution cannot proceed without a valid client. Please check your API key and network connection. !!!\")\n",
        "    # Setting client back to None to prevent further attempts if initialization failed\n",
        "    client = None\n",
        "\n",
        "print(\"Client setup step complete.\")\n",
        "print(\"-\" * 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQOg1QRZk6aV",
        "outputId": "e6d6d541-425b-4484-baa5-4bfd5060f113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to initialize the Nebius AI client...\n",
            "Nebius AI client initialized successfully. Ready to make API calls.\n",
            "Client setup step complete.\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cosine_similarity(text1, text2, client, embedding_model):\n",
        "    \"\"\"Calculates cosine similarity between the embeddings of two texts.\n",
        "\n",
        "    Args:\n",
        "        text1 (str): The first text string.\n",
        "        text2 (str): The second text string.\n",
        "        client (OpenAI): The initialized Nebius AI client.\n",
        "        embedding_model (str): The name of the embedding model to use.\n",
        "\n",
        "    Returns:\n",
        "        float: The cosine similarity score (between 0.0 and 1.0), or 0.0 if an error occurs.\n",
        "    \"\"\"\n",
        "    if not client:\n",
        "        print(\"  Error: Nebius client not available for similarity calculation.\")\n",
        "        return 0.0\n",
        "    if not text1 or not text2:\n",
        "        # Handle cases where one or both texts might be empty or None\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Generate embeddings for both texts in a single API call if possible\n",
        "        response = client.embeddings.create(model=embedding_model, input=[text1, text2])\n",
        "\n",
        "        # Extract the embedding vectors\n",
        "        embedding1 = np.array(response.data[0].embedding)\n",
        "        embedding2 = np.array(response.data[1].embedding)\n",
        "\n",
        "        # Reshape vectors to be 2D arrays as expected by cosine_similarity\n",
        "        embedding1 = embedding1.reshape(1, -1)\n",
        "        embedding2 = embedding2.reshape(1, -1)\n",
        "\n",
        "        # Calculate cosine similarity using scikit-learn\n",
        "        # cosine_similarity returns a 2D array, e.g., [[similarity]], so we extract the value.\n",
        "        similarity_score = cosine_similarity(embedding1, embedding2)[0][0]\n",
        "\n",
        "        # Clamp the score between 0.0 and 1.0 for safety/consistency\n",
        "        return max(0.0, min(1.0, similarity_score))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error calculating cosine similarity: {e}\")\n",
        "        return 0.0 # Return 0.0 in case of any API or calculation errors\n",
        "\n",
        "# --- Quick Test ---\n",
        "print(\"Defining the 'calculate_cosine_similarity' function.\")\n",
        "if client: # Only run test if client is initialized\n",
        "    test_sim = calculate_cosine_similarity(\"apple\", \"orange\", client, NEBIUS_EMBEDDING_MODEL)\n",
        "    print(f\"Testing similarity function: Similarity between 'apple' and 'orange' = {test_sim:.2f}\")\n",
        "else:\n",
        "    print(\"Skipping similarity function test as Nebius client is not initialized.\")\n",
        "print(\"-\" * 25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqLtmJvglF6R",
        "outputId": "fa46ea6f-5cc2-4025-caaa-0b3f70fa7124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defining the 'calculate_cosine_similarity' function.\n",
            "Testing similarity function: Similarity between 'apple' and 'orange' = 0.77\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store the detailed results from each experimental run\n",
        "all_results = []\n",
        "\n",
        "# --- Cache variables for Chunking/Embedding/Indexing ---\n",
        "# These variables help us avoid redundant computations when only 'top_k' changes.\n",
        "last_chunk_size = -1      # Stores the chunk_size used in the previous iteration\n",
        "last_overlap = -1         # Stores the chunk_overlap used in the previous iteration\n",
        "current_index = None      # Holds the active FAISS index\n",
        "current_chunks = []       # Holds the list of text chunks for the active settings\n",
        "current_embeddings = None # Holds the numpy array of embeddings for the active chunks\n",
        "\n",
        "# Check if the Nebius client was initialized successfully before starting\n",
        "if not client:\n",
        "    print(\"STOPPING: Nebius AI client is not initialized. Cannot run experiment.\")\n",
        "else:\n",
        "    print(\"=== Starting RAG Experiment Loop ===\\n\")\n",
        "\n",
        "    # Create all possible combinations of the tuning parameters\n",
        "    param_combinations = list(itertools.product(\n",
        "        CHUNK_SIZES_TO_TEST,\n",
        "        CHUNK_OVERLAPS_TO_TEST,\n",
        "        RETRIEVAL_TOP_K_TO_TEST\n",
        "    ))\n",
        "\n",
        "    print(f\"Total parameter combinations to test: {len(param_combinations)}\")\n",
        "\n",
        "    # --- Main Loop ---\n",
        "    # Iterate through each combination (chunk_size, chunk_overlap, top_k)\n",
        "    # Use tqdm to display a progress bar.\n",
        "    for chunk_size, chunk_overlap, top_k in tqdm(param_combinations, desc=\"Testing Configurations\"):\n",
        "\n",
        "        # --- 8.1 Processing a Chunking Configuration ---\n",
        "        # Check if chunk settings have changed, requiring re-processing.\n",
        "        if chunk_size != last_chunk_size or chunk_overlap != last_overlap:\n",
        "            # Uncomment the line below for more verbose logging during execution\n",
        "            # print(f\"\\n--- Processing New Chunk Config: Size={chunk_size}, Overlap={chunk_overlap} ---\")\n",
        "\n",
        "            # Update cache variables\n",
        "            last_chunk_size, last_overlap = chunk_size, chunk_overlap\n",
        "            # Reset index, chunks, and embeddings for the new configuration\n",
        "            current_index = None\n",
        "            current_chunks = []\n",
        "            current_embeddings = None\n",
        "\n",
        "            # --- 8.1a: Chunking ---\n",
        "            # Apply the chunk_text function to each document in the corpus\n",
        "            try:\n",
        "                # print(\"  Chunking documents...\") # Uncomment for verbose logging\n",
        "                temp_chunks = []\n",
        "                for doc_index, doc in enumerate(corpus_texts):\n",
        "                    doc_chunks = chunk_text(doc, chunk_size, chunk_overlap)\n",
        "                    if not doc_chunks:\n",
        "                         print(f\"  Warning: No chunks created for document {doc_index} with size={chunk_size}, overlap={chunk_overlap}. Skipping document.\")\n",
        "                         continue\n",
        "                    temp_chunks.extend(doc_chunks)\n",
        "\n",
        "                current_chunks = temp_chunks\n",
        "                if not current_chunks:\n",
        "                    # If no chunks were created at all (e.g., due to invalid settings or empty corpus)\n",
        "                    raise ValueError(\"No chunks were created for the current configuration.\")\n",
        "                # print(f\"    Created {len(current_chunks)} chunks total.\") # Uncomment for verbose logging\n",
        "            except Exception as e:\n",
        "                 print(f\"    ERROR during chunking for Size={chunk_size}, Overlap={chunk_overlap}: {e}. Skipping this configuration.\")\n",
        "                 last_chunk_size, last_overlap = -1, -1 # Reset cache state\n",
        "                 continue # Move to the next parameter combination\n",
        "\n",
        "            # --- 8.1b: Embedding ---\n",
        "            # Generate embeddings for all chunks using the Nebius API.\n",
        "            # print(\"  Generating embeddings...\") # Uncomment for verbose logging\n",
        "            try:\n",
        "                batch_size = 32 # Process chunks in batches to avoid overwhelming the API or hitting limits.\n",
        "                temp_embeddings = [] # Temporary list to store embedding vectors\n",
        "\n",
        "                # Loop through chunks in batches\n",
        "                for i in range(0, len(current_chunks), batch_size):\n",
        "                    batch_texts = current_chunks[i : min(i + batch_size, len(current_chunks))]\n",
        "                    # Make the API call to Nebius for the current batch\n",
        "                    response = client.embeddings.create(model=NEBIUS_EMBEDDING_MODEL, input=batch_texts)\n",
        "                    # Extract the embedding vectors from the API response\n",
        "                    batch_embeddings = [item.embedding for item in response.data]\n",
        "                    temp_embeddings.extend(batch_embeddings)\n",
        "                    time.sleep(0.05) # Add a small delay between batches to be polite to the API endpoint.\n",
        "\n",
        "                # Convert the list of embeddings into a single NumPy array\n",
        "                current_embeddings = np.array(temp_embeddings)\n",
        "                # Basic validation check on the embeddings array\n",
        "                if current_embeddings.ndim != 2 or current_embeddings.shape[0] != len(current_chunks):\n",
        "                    raise ValueError(f\"Embeddings array shape mismatch. Expected ({len(current_chunks)}, dim), Got {current_embeddings.shape}\")\n",
        "                # print(f\"    Generated {current_embeddings.shape[0]} embeddings (Dimension: {current_embeddings.shape[1]}).\") # Uncomment for verbose logging\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    ERROR generating embeddings for Size={chunk_size}, Overlap={chunk_overlap}: {e}. Skipping this chunk config.\")\n",
        "                # Reset cache variables to indicate failure for this chunk setting\n",
        "                last_chunk_size, last_overlap = -1, -1\n",
        "                current_chunks = []\n",
        "                current_embeddings = None\n",
        "                continue # Skip to the next parameter combination\n",
        "\n",
        "            # --- 8.1c: Indexing ---\n",
        "            # Build a FAISS index for efficient similarity search.\n",
        "            # print(\"  Building FAISS search index...\") # Uncomment for verbose logging\n",
        "            try:\n",
        "                embedding_dim = current_embeddings.shape[1] # Get the dimensionality of the embeddings\n",
        "                # We use IndexFlatL2, which performs exact search using L2 (Euclidean) distance.\n",
        "                # For high-dimensional vectors from modern embedding models, cosine similarity often works better,\n",
        "                # but FAISS's IndexFlatIP (Inner Product) is closely related. For normalized embeddings (like many BGE models),\n",
        "                # L2 distance and Inner Product/Cosine Similarity ranking are equivalent.\n",
        "                current_index = faiss.IndexFlatL2(embedding_dim)\n",
        "                # Add the chunk embeddings to the index. FAISS requires float32 data type.\n",
        "                current_index.add(current_embeddings.astype('float32'))\n",
        "\n",
        "                if current_index.ntotal == 0:\n",
        "                     raise ValueError(\"FAISS index is empty after adding vectors. No vectors were added.\")\n",
        "                # print(f\"    FAISS index ready with {current_index.ntotal} vectors.\") # Uncomment for verbose logging\n",
        "            except Exception as e:\n",
        "                print(f\"    ERROR building FAISS index for Size={chunk_size}, Overlap={chunk_overlap}: {e}. Skipping this chunk config.\")\n",
        "                # Reset variables to indicate failure\n",
        "                last_chunk_size, last_overlap = -1, -1\n",
        "                current_index = None\n",
        "                current_embeddings = None\n",
        "                current_chunks = []\n",
        "                continue # Skip to the next parameter combination\n",
        "\n",
        "        # --- 8.2 Testing RAG Strategies for the Current Top-K ---\n",
        "        # If we reach this point, we have a valid index and chunks for the current chunk_size/overlap.\n",
        "\n",
        "        # Check if the index and chunks are actually available (safety check)\n",
        "        if current_index is None or not current_chunks:\n",
        "            print(f\"    WARNING: Index or chunks not available for Size={chunk_size}, Overlap={chunk_overlap}. Skipping Top-K={top_k} test.\")\n",
        "            continue\n",
        "\n",
        "        # --- 8.3 Running & Evaluating a Single RAG Strategy ---\n",
        "        # Define a nested function to perform the core RAG steps (retrieve, generate, evaluate)\n",
        "        # This avoids code repetition for each strategy.\n",
        "        def run_and_evaluate(strategy_name, query_to_use, k_retrieve, use_simulated_rerank=False):\n",
        "            # print(f\"    Starting: {strategy_name} (k={k_retrieve}) ...\") # Uncomment for verbose logging\n",
        "            run_start_time = time.time() # Record start time for timing the run\n",
        "\n",
        "            # Initialize a dictionary to store results for this specific run\n",
        "            result = {\n",
        "                'chunk_size': chunk_size, 'overlap': chunk_overlap, 'top_k': k_retrieve,\n",
        "                'strategy': strategy_name,\n",
        "                'retrieved_indices': [], 'rewritten_query': None, 'answer': 'Error: Execution Failed',\n",
        "                'faithfulness': 0.0, 'relevancy': 0.0, 'similarity_score': 0.0, 'avg_score': 0.0,\n",
        "                'time_sec': 0.0\n",
        "            }\n",
        "            # Store the rewritten query if applicable\n",
        "            if strategy_name == \"Query Rewrite RAG\":\n",
        "                result['rewritten_query'] = query_to_use\n",
        "\n",
        "            try:\n",
        "                # --- Retrieval Step ---\n",
        "                k_for_search = k_retrieve # Number of chunks to retrieve initially\n",
        "                if use_simulated_rerank:\n",
        "                    # For simulated rerank, retrieve more candidates initially\n",
        "                    k_for_search = k_retrieve * RERANK_RETRIEVAL_MULTIPLIER\n",
        "                    # print(f\"      Rerank: Retrieving initial {k_for_search} candidates.\") # Uncomment for verbose logging\n",
        "\n",
        "                # 1. Embed the query (original or rewritten)\n",
        "                query_embedding_response = client.embeddings.create(model=NEBIUS_EMBEDDING_MODEL, input=[query_to_use])\n",
        "                query_embedding = query_embedding_response.data[0].embedding\n",
        "                query_vector = np.array([query_embedding]).astype('float32') # FAISS needs float32 numpy array\n",
        "\n",
        "                # 2. Perform the search in the FAISS index\n",
        "                # Ensure k is not greater than the total number of items in the index\n",
        "                actual_k = min(k_for_search, current_index.ntotal)\n",
        "                if actual_k == 0:\n",
        "                    raise ValueError(\"Index is empty or k_for_search is zero, cannot search.\")\n",
        "\n",
        "                # `current_index.search` returns distances and indices of the nearest neighbors\n",
        "                distances, indices = current_index.search(query_vector, actual_k)\n",
        "\n",
        "                # 3. Process retrieved indices\n",
        "                # Indices can contain -1 if fewer than 'actual_k' vectors are found (shouldn't happen with IndexFlatL2 unless k > ntotal)\n",
        "                retrieved_indices_all = indices[0]\n",
        "                valid_indices = retrieved_indices_all[retrieved_indices_all != -1].tolist()\n",
        "\n",
        "                # 4. Apply simulated reranking (if applicable)\n",
        "                # In this simulation, we just take the top 'k_retrieve' results from the initially retrieved set.\n",
        "                # A real reranker would re-score these 'k_for_search' candidates based on relevance to the query.\n",
        "                if use_simulated_rerank:\n",
        "                    final_indices = valid_indices[:k_retrieve]\n",
        "                    # print(f\"      Rerank: Selected top {len(final_indices)} indices after simulated rerank.\") # Uncomment for verbose logging\n",
        "                else:\n",
        "                    final_indices = valid_indices # Use all valid retrieved indices up to k_retrieve\n",
        "\n",
        "                result['retrieved_indices'] = final_indices\n",
        "\n",
        "                # 5. Get the actual text chunks corresponding to the final indices\n",
        "                retrieved_chunks = [current_chunks[i] for i in final_indices]\n",
        "\n",
        "                # Handle case where no chunks were retrieved (should be rare with valid indices)\n",
        "                if not retrieved_chunks:\n",
        "                    print(f\"      Warning: No relevant chunks found for {strategy_name} (C={chunk_size}, O={chunk_overlap}, K={k_retrieve}). Setting answer to indicate this.\")\n",
        "                    result['answer'] = \"No relevant context found in the documents based on the query.\"\n",
        "                    # Keep scores at 0.0 as no answer was generated from context\n",
        "                else:\n",
        "                    # --- Generation Step ---\n",
        "                    # Combine the retrieved chunks into a single context string\n",
        "                    context_str = \"\\n\\n\".join(retrieved_chunks)\n",
        "\n",
        "                    # Define the system prompt for the generation LLM\n",
        "                    sys_prompt_gen = \"You are a helpful AI assistant. Answer the user's query based strictly on the provided context. If the context doesn't contain the answer, state that clearly. Be concise.\"\n",
        "\n",
        "                    # Construct the user prompt including the context and the *original* query\n",
        "                    # It's important to use the original query here for generating the final answer, even if a rewritten query was used for retrieval.\n",
        "                    user_prompt_gen = f\"Context:\\n------\\n{context_str}\\n------\\n\\nQuery: {test_query}\\n\\nAnswer:\"\n",
        "\n",
        "                    # Make the API call to the Nebius generation model\n",
        "                    gen_response = client.chat.completions.create(\n",
        "                        model=NEBIUS_GENERATION_MODEL,\n",
        "                        messages=[\n",
        "                            {\"role\": \"system\", \"content\": sys_prompt_gen},\n",
        "                            {\"role\": \"user\", \"content\": user_prompt_gen}\n",
        "                        ],\n",
        "                        temperature=GENERATION_TEMPERATURE,\n",
        "                        max_tokens=GENERATION_MAX_TOKENS,\n",
        "                        top_p=GENERATION_TOP_P\n",
        "                    )\n",
        "                    # Extract the generated text answer\n",
        "                    generated_answer = gen_response.choices[0].message.content.strip()\n",
        "                    result['answer'] = generated_answer\n",
        "                    # Optional: print a snippet of the generated answer\n",
        "                    # print(f\"      Generated Answer: {generated_answer[:100].replace('\\n', ' ')}...\")\n",
        "\n",
        "                    # --- Evaluation Step ---\n",
        "                    # Evaluate the generated answer using Faithfulness, Relevancy, and Similarity\n",
        "                    # print(f\"      Evaluating answer... (Faithfulness, Relevancy, Similarity)\") # Uncomment for verbose logging\n",
        "\n",
        "                    # Prepare parameters for evaluation calls (use low temperature for deterministic scoring)\n",
        "                    eval_params = {'model': NEBIUS_EVALUATION_MODEL, 'temperature': 0.0, 'max_tokens': 10}\n",
        "\n",
        "                    # 1. Faithfulness Evaluation Call\n",
        "                    prompt_f = FAITHFULNESS_PROMPT.format(question=test_query, response=generated_answer, true_answer=true_answer_for_query)\n",
        "                    try:\n",
        "                        resp_f = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": prompt_f}], **eval_params)\n",
        "                        # Attempt to parse the score, clamp between 0.0 and 1.0\n",
        "                        result['faithfulness'] = max(0.0, min(1.0, float(resp_f.choices[0].message.content.strip())))\n",
        "                    except Exception as eval_e:\n",
        "                        print(f\"      Warning: Faithfulness score parsing error for {strategy_name} - {eval_e}. Score set to 0.0\")\n",
        "                        result['faithfulness'] = 0.0\n",
        "\n",
        "                    # 2. Relevancy Evaluation Call\n",
        "                    prompt_r = RELEVANCY_PROMPT.format(question=test_query, response=generated_answer)\n",
        "                    try:\n",
        "                        resp_r = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": prompt_r}], **eval_params)\n",
        "                        # Attempt to parse the score, clamp between 0.0 and 1.0\n",
        "                        result['relevancy'] = max(0.0, min(1.0, float(resp_r.choices[0].message.content.strip())))\n",
        "                    except Exception as eval_e:\n",
        "                        print(f\"      Warning: Relevancy score parsing error for {strategy_name} - {eval_e}. Score set to 0.0\")\n",
        "                        result['relevancy'] = 0.0\n",
        "\n",
        "                    # 3. Similarity Score Calculation\n",
        "                    result['similarity_score'] = calculate_cosine_similarity(\n",
        "                        generated_answer,\n",
        "                        true_answer_for_query,\n",
        "                        client,\n",
        "                        NEBIUS_EMBEDDING_MODEL\n",
        "                    )\n",
        "\n",
        "                    # 4. Calculate Average Score (Faithfulness, Relevancy, Similarity)\n",
        "                    result['avg_score'] = (result['faithfulness'] + result['relevancy'] + result['similarity_score']) / 3.0\n",
        "\n",
        "            except Exception as e:\n",
        "                # Catch any unexpected errors during the retrieve/generate/evaluate process\n",
        "                error_message = f\"ERROR during {strategy_name} (C={chunk_size}, O={chunk_overlap}, K={k_retrieve}): {str(e)[:200]}...\"\n",
        "                print(f\"    {error_message}\")\n",
        "                result['answer'] = error_message # Store the error in the answer field\n",
        "                # Ensure scores remain at their default error state (0.0)\n",
        "                result['faithfulness'] = 0.0\n",
        "                result['relevancy'] = 0.0\n",
        "                result['similarity_score'] = 0.0\n",
        "                result['avg_score'] = 0.0\n",
        "\n",
        "            # Record the total time taken for this run\n",
        "            run_end_time = time.time()\n",
        "            result['time_sec'] = run_end_time - run_start_time\n",
        "\n",
        "            # Print a summary line for this run (useful for monitoring progress)\n",
        "            print(f\"    Finished: {strategy_name} (C={chunk_size}, O={chunk_overlap}, K={k_retrieve}). AvgScore={result['avg_score']:.2f}, Time={result['time_sec']:.2f}s\")\n",
        "            return result\n",
        "        # --- End of run_and_evaluate nested function ---\n",
        "\n",
        "        # --- Execute the RAG Strategies using the run_and_evaluate function ---\n",
        "\n",
        "        # Strategy 1: Simple RAG (Use original query for retrieval)\n",
        "        result_simple = run_and_evaluate(\"Simple RAG\", test_query, top_k)\n",
        "        all_results.append(result_simple)\n",
        "\n",
        "        # Strategy 2: Query Rewrite RAG\n",
        "        rewritten_q = test_query # Default to original query if rewrite fails\n",
        "        try:\n",
        "             # print(\"    Attempting query rewrite for Rewrite RAG...\") # Uncomment for verbose logging\n",
        "             # Define prompts for the query rewriting task\n",
        "             sys_prompt_rw = \"You are an expert query optimizer. Rewrite the user's query to be ideal for vector database retrieval. Focus on key entities, concepts, and relationships. Remove conversational fluff. Output ONLY the rewritten query text.\"\n",
        "             user_prompt_rw = f\"Original Query: {test_query}\\n\\nRewritten Query:\"\n",
        "\n",
        "             # Call the LLM to rewrite the query\n",
        "             resp_rw = client.chat.completions.create(\n",
        "                 model=NEBIUS_GENERATION_MODEL, # Can use the generation model for this task too\n",
        "                 messages=[\n",
        "                     {\"role\": \"system\", \"content\": sys_prompt_rw},\n",
        "                     {\"role\": \"user\", \"content\": user_prompt_rw}\n",
        "                 ],\n",
        "                 temperature=0.1, # Low temp for focused rewrite\n",
        "                 max_tokens=100,\n",
        "                 top_p=0.9\n",
        "             )\n",
        "             # Clean up the LLM's response to get just the query text\n",
        "             candidate_q = resp_rw.choices[0].message.content.strip()\n",
        "             # Remove potential prefixes like \"Rewritten Query:\" or \"Query:\"\n",
        "             candidate_q = re.sub(r'^(rewritten query:|query:)\\s*', '', candidate_q, flags=re.IGNORECASE).strip('\"')\n",
        "\n",
        "             # Use the rewritten query only if it's reasonably different and not too short\n",
        "             if candidate_q and len(candidate_q) > 5 and candidate_q.lower() != test_query.lower():\n",
        "                 rewritten_q = candidate_q\n",
        "                 # print(f\"      Using rewritten query: '{rewritten_q}'\") # Uncomment for verbose logging\n",
        "             # else:\n",
        "                 # print(\"      Rewrite failed, too short, or same as original. Using original query.\") # Uncomment for verbose logging\n",
        "        except Exception as e:\n",
        "             print(f\"    Warning: Error during query rewrite: {e}. Using original query.\")\n",
        "             rewritten_q = test_query # Fallback to original query on error\n",
        "\n",
        "        # Run evaluation using the (potentially) rewritten query for retrieval\n",
        "        result_rewrite = run_and_evaluate(\"Query Rewrite RAG\", rewritten_q, top_k)\n",
        "        all_results.append(result_rewrite)\n",
        "\n",
        "        # Strategy 3: Rerank RAG (Simulated)\n",
        "        # Use original query for retrieval, but simulate the reranking process\n",
        "        result_rerank = run_and_evaluate(\"Rerank RAG (Simulated)\", test_query, top_k, use_simulated_rerank=True)\n",
        "        all_results.append(result_rerank)\n",
        "\n",
        "    print(\"\\n=== RAG Experiment Loop Finished ===\")\n",
        "    print(\"-\" * 25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570,
          "referenced_widgets": [
            "f1dac85df23c419cb431b768b445b96b",
            "c111da38c52546489a0f334123e28714",
            "45811aeed8f243478d479f43ded013ac",
            "2e145e34a07f4c25bba5d4e8e1e6c797",
            "8b077dee05f4498ea56bcd636cca71f1",
            "c1237649f66c450ab9517a2c309e8fc5",
            "1876d13a3337443fb14f7a8de3a2ac0c",
            "77949978ca184281bbe71511bec0eefe",
            "b218901e46634732b8e83f8437d1e680",
            "02e7eb82dc3447b9849475e2f79928d6",
            "9c5f585e61c5408b92968e63bc8de7aa"
          ]
        },
        "id": "qKKbdJMLlJu-",
        "outputId": "3117066f-0f88-4807-8ffb-5b8d66c0d772"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Starting RAG Experiment Loop ===\n",
            "\n",
            "Total parameter combinations to test: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing Configurations:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1dac85df23c419cb431b768b445b96b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Finished: Simple RAG (C=150, O=30, K=3). AvgScore=0.90, Time=8.76s\n",
            "    Finished: Query Rewrite RAG (C=150, O=30, K=3). AvgScore=0.90, Time=10.22s\n",
            "    Finished: Rerank RAG (Simulated) (C=150, O=30, K=3). AvgScore=0.89, Time=8.36s\n",
            "    Finished: Simple RAG (C=150, O=30, K=5). AvgScore=0.89, Time=10.93s\n",
            "    Finished: Query Rewrite RAG (C=150, O=30, K=5). AvgScore=0.89, Time=9.16s\n",
            "    Finished: Rerank RAG (Simulated) (C=150, O=30, K=5). AvgScore=0.89, Time=10.66s\n",
            "    Finished: Simple RAG (C=150, O=50, K=3). AvgScore=0.90, Time=8.65s\n",
            "    Finished: Query Rewrite RAG (C=150, O=50, K=3). AvgScore=0.90, Time=10.13s\n",
            "    Finished: Rerank RAG (Simulated) (C=150, O=50, K=3). AvgScore=0.90, Time=7.99s\n",
            "    Finished: Simple RAG (C=150, O=50, K=5). AvgScore=0.89, Time=9.25s\n",
            "    Finished: Query Rewrite RAG (C=150, O=50, K=5). AvgScore=0.89, Time=9.63s\n",
            "    Finished: Rerank RAG (Simulated) (C=150, O=50, K=5). AvgScore=0.89, Time=9.57s\n",
            "    Finished: Simple RAG (C=250, O=30, K=3). AvgScore=0.89, Time=9.84s\n",
            "    Finished: Query Rewrite RAG (C=250, O=30, K=3). AvgScore=0.89, Time=14.33s\n",
            "    Finished: Rerank RAG (Simulated) (C=250, O=30, K=3). AvgScore=0.90, Time=9.77s\n",
            "    Finished: Simple RAG (C=250, O=30, K=5). AvgScore=0.89, Time=8.91s\n",
            "    Finished: Query Rewrite RAG (C=250, O=30, K=5). AvgScore=0.89, Time=9.47s\n",
            "    Finished: Rerank RAG (Simulated) (C=250, O=30, K=5). AvgScore=0.89, Time=8.34s\n",
            "    Finished: Simple RAG (C=250, O=50, K=3). AvgScore=0.90, Time=11.45s\n",
            "    Finished: Query Rewrite RAG (C=250, O=50, K=3). AvgScore=0.89, Time=9.13s\n",
            "    Finished: Rerank RAG (Simulated) (C=250, O=50, K=3). AvgScore=0.89, Time=9.31s\n",
            "    Finished: Simple RAG (C=250, O=50, K=5). AvgScore=0.89, Time=10.07s\n",
            "    Finished: Query Rewrite RAG (C=250, O=50, K=5). AvgScore=0.89, Time=11.73s\n",
            "    Finished: Rerank RAG (Simulated) (C=250, O=50, K=5). AvgScore=0.89, Time=8.96s\n",
            "\n",
            "=== RAG Experiment Loop Finished ===\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(current_index)\n",
        "print('embeddings shape: ',current_embeddings.shape)\n",
        "print('corpus length: ',len(corpus_texts))\n",
        "print('chunks length: ',len(current_chunks))\n",
        "for l in all_results:\n",
        "  print(l)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9MgA-I7_Kgn",
        "outputId": "8615a66c-5a4f-475d-f241-7158d4ebd189"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7db95bcd9fe0> >\n",
            "embeddings shape:  (5, 3584)\n",
            "corpus length:  5\n",
            "chunks length:  5\n",
            "{'chunk_size': 150, 'overlap': 30, 'top_k': 3, 'strategy': 'Simple RAG', 'retrieved_indices': [2, 0, 3], 'rewritten_query': None, 'answer': '**Consistency:**\\n- **Hydropower** is highly reliable and provides consistent, large-scale power, as it is not dependent on weather conditions once the dam is operational.\\n- **Solar power** is less consistent due to its dependence on sunlight, which varies with weather and time of day. Storage solutions like batteries are essential to mitigate this variability.\\n\\n**Environmental Impact:**\\n- **Hydropower** has significant environmental impacts, including ecosystem disruption and community displacement, especially with large dams. Run-of-river systems are less disruptive but still affect local ecosystems.\\n- **Solar power** is cleaner with minimal environmental impact during operation, though the production and disposal of PV panels can have environmental consequences. It does not disrupt ecosystems or displace communities.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7901125197890381), 'avg_score': np.float64(0.8967041732630127), 'time_sec': 8.755533218383789}\n",
            "{'chunk_size': 150, 'overlap': 30, 'top_k': 3, 'strategy': 'Query Rewrite RAG', 'retrieved_indices': [2, 0, 3], 'rewritten_query': 'solar power consistency environmental impact vs hydropower consistency environmental impact', 'answer': '**Consistency:**\\n- **Hydropower** is highly consistent and reliable, providing large-scale power 24/7, as it is not dependent on weather or time of day.\\n- **Solar power** is less consistent, as it varies with weather conditions and time of day (sunlight availability). Storage solutions like batteries are essential to improve its reliability.\\n\\n**Environmental Impact:**\\n- **Hydropower** has significant environmental impacts, particularly from large dams, which can harm ecosystems, disrupt fish migration, and displace communities. Run-of-river systems are less disruptive but still have some ecological effects.\\n- **Solar power** is cleaner with minimal environmental impact during operation. However, the production and disposal of PV panels can have environmental consequences, and large solar farms may affect land use.\\n\\nIn summary, hydropower offers more consistent energy but with greater environmental disruption, while solar power is cleaner but less consistent without storage solutions.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7856196912458369), 'avg_score': np.float64(0.8952065637486122), 'time_sec': 10.219137191772461}\n",
            "{'chunk_size': 150, 'overlap': 30, 'top_k': 3, 'strategy': 'Rerank RAG (Simulated)', 'retrieved_indices': [2, 0, 3], 'rewritten_query': None, 'answer': '**Consistency:**  \\n- **Hydropower** is highly reliable and provides consistent, large-scale power, especially with dams that can store water and regulate flow.  \\n- **Solar power** is less consistent as it varies with weather and time of day, requiring storage solutions like batteries for more reliable output.  \\n\\n**Environmental Impact:**  \\n- **Hydropower** can have significant environmental impacts, including ecosystem disruption and community displacement, particularly with large dams. Run-of-river systems are less disruptive but still affect local habitats.  \\n- **Solar power** is cleaner with minimal environmental impact during operation, though manufacturing and disposal of panels can have ecological consequences.  \\n\\nIn summary, hydropower is more consistent but has greater environmental impacts, while solar power is less consistent but generally cleaner.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7736185954083926), 'avg_score': np.float64(0.8912061984694643), 'time_sec': 8.362337112426758}\n",
            "{'chunk_size': 150, 'overlap': 30, 'top_k': 5, 'strategy': 'Simple RAG', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': None, 'answer': '**Consistency:**\\n- **Solar Power:** Inconsistent due to dependence on weather and daylight. Requires storage solutions like batteries for consistent supply.\\n- **Hydropower:** Highly reliable and consistent, providing large-scale power 24/7, especially with dams.\\n\\n**Environmental Impact:**\\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing panels involves resource use and potential pollution. Land use can also impact ecosystems.\\n- **Hydropower:** Large dams significantly disrupt ecosystems, displace communities, and alter water flow. Run-of-river systems are less disruptive but still impact local environments.\\n\\nIn summary, hydropower offers more consistent energy but has greater environmental impacts, particularly with large dams. Solar power is cleaner but less consistent, requiring storage for reliability.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7757093844556726), 'avg_score': np.float64(0.8919031281518909), 'time_sec': 10.934330940246582}\n",
            "{'chunk_size': 150, 'overlap': 30, 'top_k': 5, 'strategy': 'Query Rewrite RAG', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': 'solar power consistency environmental impact vs hydropower consistency environmental impact', 'answer': '**Consistency:**  \\n- **Solar Power:** Inconsistent due to dependence on weather and daylight. Requires storage solutions (e.g., batteries) for reliable power.  \\n- **Hydropower:** Highly reliable and consistent, as it can generate power continuously, especially with large dams that store water.  \\n\\n**Environmental Impact:**  \\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing PV panels involves resource use and potential pollution. Land use can also impact ecosystems.  \\n- **Hydropower:** Large dams significantly disrupt ecosystems, alter water flow, and displace communities. Run-of-river systems are less harmful but still impact local environments.  \\n\\nIn summary, hydropower is more consistent but has greater environmental disruption, while solar power is cleaner but less consistent without storage.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.772509565341623), 'avg_score': np.float64(0.8908365217805411), 'time_sec': 9.157312870025635}\n",
            "{'chunk_size': 150, 'overlap': 30, 'top_k': 5, 'strategy': 'Rerank RAG (Simulated)', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': None, 'answer': '**Consistency:**\\n- **Solar Power:** Inconsistent due to dependence on weather and time of day. Requires storage solutions (e.g., batteries) for reliable power supply.\\n- **Hydropower:** Highly reliable and consistent, as it can generate power continuously, especially with large-scale dams.\\n\\n**Environmental Impact:**\\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing PV panels involves resource extraction and energy use. Land use for large solar farms can impact ecosystems.\\n- **Hydropower:** Large dams can significantly harm ecosystems, disrupt fish migration, and displace communities. Run-of-river systems are less disruptive but still impact local environments. Hydropower is generally clean in terms of emissions during operation. \\n\\nIn summary, hydropower offers more consistent energy but has greater environmental impacts, particularly with large dams. Solar power is cleaner but less consistent, requiring storage for reliability.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7713965201203054), 'avg_score': np.float64(0.8904655067067684), 'time_sec': 10.660796165466309}\n",
            "{'chunk_size': 150, 'overlap': 50, 'top_k': 3, 'strategy': 'Simple RAG', 'retrieved_indices': [2, 0, 3], 'rewritten_query': None, 'answer': '**Consistency:**\\n- **Hydropower** is highly reliable and provides consistent, large-scale power, as it is not dependent on weather conditions once the dam is operational.\\n- **Solar power** is less consistent because it varies with weather and time of day. Storage solutions like batteries are essential to ensure a steady supply.\\n\\n**Environmental Impact:**\\n- **Hydropower** can have significant environmental impacts, including ecosystem disruption and community displacement, especially with large dams. Run-of-river systems are less disruptive but still affect local habitats.\\n- **Solar power** is cleaner with minimal environmental impact during operation, though manufacturing PV panels and CSP systems involves resource use and potential pollution. It does not disrupt ecosystems or displace communities.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.8015336725150428), 'avg_score': np.float64(0.900511224171681), 'time_sec': 8.653193712234497}\n",
            "{'chunk_size': 150, 'overlap': 50, 'top_k': 3, 'strategy': 'Query Rewrite RAG', 'retrieved_indices': [2, 0, 3], 'rewritten_query': 'solar power consistency environmental impact vs hydropower consistency environmental impact', 'answer': '**Consistency:**\\n- **Hydropower** is highly reliable and provides consistent, large-scale power, as it is not dependent on weather conditions or time of day.\\n- **Solar power** is less consistent because it varies with weather and time (day/night cycles). Storage solutions like batteries are essential to maintain a steady supply.\\n\\n**Environmental Impact:**\\n- **Hydropower** has significant environmental impacts, including ecosystem disruption and community displacement, especially with large dams. Run-of-river systems are less disruptive but still affect local ecosystems.\\n- **Solar power** is cleaner with minimal environmental impact during operation, but the production and disposal of PV panels can have ecological consequences. CSP systems may require large land areas and affect local habitats. \\n\\nIn summary, hydropower is more consistent but has greater environmental impacts, while solar power is less consistent but generally cleaner environmentally.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7865102584706731), 'avg_score': np.float64(0.8955034194902244), 'time_sec': 10.127140045166016}\n",
            "{'chunk_size': 150, 'overlap': 50, 'top_k': 3, 'strategy': 'Rerank RAG (Simulated)', 'retrieved_indices': [2, 0, 3], 'rewritten_query': None, 'answer': '**Consistency:**\\n- **Hydropower** is highly reliable and consistent, providing large-scale power 24/7, as it relies on the continuous flow of water.\\n- **Solar power** is less consistent, as it depends on weather conditions and daylight availability. Storage solutions like batteries are essential to mitigate this variability.\\n\\n**Environmental Impact:**\\n- **Hydropower** has significant environmental impacts, including ecosystem disruption and community displacement, especially with large dams. Run-of-river systems are less disruptive but still affect local ecosystems.\\n- **Solar power** is cleaner with minimal environmental impact during operation, though manufacturing and disposal of PV panels can have ecological consequences. It does not disrupt ecosystems or displace communities.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7867984069633087), 'avg_score': np.float64(0.8955994689877697), 'time_sec': 7.994071006774902}\n",
            "{'chunk_size': 150, 'overlap': 50, 'top_k': 5, 'strategy': 'Simple RAG', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': None, 'answer': '**Consistency:**  \\n- **Solar Power:** Inconsistent due to dependence on weather and daylight. Requires storage solutions (e.g., batteries) for reliable power.  \\n- **Hydropower:** Highly reliable and consistent, as it can generate power continuously, especially with large dams that store water.  \\n\\n**Environmental Impact:**  \\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing panels involves resource use and potential waste.  \\n- **Hydropower:** Large dams can significantly harm ecosystems, disrupt fish migration, and displace communities. Run-of-river systems are less disruptive but still impact local environments.  \\n\\nIn summary, hydropower is more consistent but has greater environmental impacts, while solar power is cleaner but less consistent without storage.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7698502633995625), 'avg_score': np.float64(0.8899500877998542), 'time_sec': 9.245346546173096}\n",
            "{'chunk_size': 150, 'overlap': 50, 'top_k': 5, 'strategy': 'Query Rewrite RAG', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': 'solar power consistency environmental impact vs hydropower consistency environmental impact', 'answer': '**Consistency:**\\n- **Solar Power:** Inconsistent due to dependence on weather and daylight. Requires storage solutions (e.g., batteries) for consistent supply.\\n- **Hydropower:** Highly reliable and consistent, as it can generate power continuously, especially with large dams that store water.\\n\\n**Environmental Impact:**\\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing panels involves resource extraction and energy use. Land use can impact ecosystems.\\n- **Hydropower:** Large dams significantly disrupt ecosystems, alter water flow, and displace communities. Run-of-river systems are less disruptive but still impact local habitats.\\n\\nIn summary, hydropower is more consistent but has greater environmental impacts, especially with large dams, while solar power is less consistent but generally cleaner, though it has its own environmental challenges.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7706731572691993), 'avg_score': np.float64(0.8902243857563997), 'time_sec': 9.632621049880981}\n",
            "{'chunk_size': 150, 'overlap': 50, 'top_k': 5, 'strategy': 'Rerank RAG (Simulated)', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': None, 'answer': '**Consistency:**  \\n- **Solar Power:** Inconsistent due to dependence on weather and daylight; requires storage (e.g., batteries) for reliable supply.  \\n- **Hydropower:** Highly reliable and consistent, as it can generate power continuously, especially with large dams.  \\n\\n**Environmental Impact:**  \\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing panels involves resource use and potential waste.  \\n- **Hydropower:** Large dams can significantly harm ecosystems, disrupt water flow, and displace communities, while run-of-river systems are less disruptive but still impact local environments.  \\n\\nIn summary, hydropower is more consistent but has greater environmental impacts, while solar power is less consistent but cleaner in operation.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7630589738407849), 'avg_score': np.float64(0.887686324613595), 'time_sec': 9.573868036270142}\n",
            "{'chunk_size': 250, 'overlap': 30, 'top_k': 3, 'strategy': 'Simple RAG', 'retrieved_indices': [2, 0, 3], 'rewritten_query': None, 'answer': '**Consistency:**\\n- **Hydropower:** Highly reliable and consistent, as it can generate electricity continuously as long as water flow is maintained. It is not dependent on weather or time of day.\\n- **Solar Power:** Less consistent, as it depends on sunlight availability. It varies with weather conditions and time of day, requiring storage solutions like batteries for consistent power supply.\\n\\n**Environmental Impact:**\\n- **Hydropower:** Large dams can significantly harm ecosystems, disrupt aquatic life, and displace communities. Run-of-river systems are less disruptive but still have some environmental impact.\\n- **Solar Power:** Generally clean with minimal environmental impact during operation. However, the production and disposal of PV panels can have environmental consequences, and large-scale installations may affect land use.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7781728693897616), 'avg_score': np.float64(0.8927242897965871), 'time_sec': 9.839802742004395}\n",
            "{'chunk_size': 250, 'overlap': 30, 'top_k': 3, 'strategy': 'Query Rewrite RAG', 'retrieved_indices': [2, 0, 3], 'rewritten_query': 'solar power vs hydropower: consistency, environmental impact', 'answer': '**Consistency:**\\n- **Hydropower:** Highly reliable and consistent, as it can generate electricity continuously as long as there is a steady water flow. It is not dependent on weather or time of day.\\n- **Solar Power:** Less consistent, as it depends on sunlight availability. It varies with weather conditions and time of day, requiring storage solutions like batteries for consistent power supply.\\n\\n**Environmental Impact:**\\n- **Hydropower:** Large dams can significantly harm ecosystems, disrupt aquatic life, and displace communities. However, run-of-river systems are less disruptive.\\n- **Solar Power:** Generally has a lower environmental impact, as it produces clean energy without emissions. However, the production and disposal of PV panels can have environmental consequences, and large-scale solar farms may impact land use.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7795772327770065), 'avg_score': np.float64(0.8931924109256689), 'time_sec': 14.330620050430298}\n",
            "{'chunk_size': 250, 'overlap': 30, 'top_k': 3, 'strategy': 'Rerank RAG (Simulated)', 'retrieved_indices': [2, 0, 3], 'rewritten_query': None, 'answer': '**Consistency:**\\n- **Hydropower** is highly reliable and provides consistent, large-scale power, as it is not dependent on weather conditions once the dam is operational.\\n- **Solar power** is less consistent because it varies with weather and time of day, requiring storage solutions like batteries to ensure a steady supply.\\n\\n**Environmental Impact:**\\n- **Hydropower** has significant environmental impacts, including ecosystem disruption and community displacement, especially with large dams. Run-of-river systems are less disruptive but still affect local ecosystems.\\n- **Solar power** is cleaner with minimal environmental impact during operation, though manufacturing and disposal of panels can have ecological consequences. It does not disrupt ecosystems or displace communities.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7962822178706115), 'avg_score': np.float64(0.8987607392902038), 'time_sec': 9.774417161941528}\n",
            "{'chunk_size': 250, 'overlap': 30, 'top_k': 5, 'strategy': 'Simple RAG', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': None, 'answer': '**Consistency:**  \\n- **Solar Power:** Inconsistent due to dependence on weather and daylight. Requires storage solutions (e.g., batteries) for reliable power.  \\n- **Hydropower:** Highly reliable and consistent, as it can generate power continuously, especially with large dams that store water.  \\n\\n**Environmental Impact:**  \\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing panels involves resource extraction and waste. Land use can impact ecosystems.  \\n- **Hydropower:** Large dams disrupt ecosystems, alter water flow, and displace communities. Run-of-river systems are less harmful but still impact local habitats.  \\n\\nIn summary, hydropower is more consistent but has greater environmental disruption, while solar power is cleaner but less consistent without storage.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7665765531816215), 'avg_score': np.float64(0.8888588510605405), 'time_sec': 8.905218362808228}\n",
            "{'chunk_size': 250, 'overlap': 30, 'top_k': 5, 'strategy': 'Query Rewrite RAG', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': 'solar power consistency environmental impact vs hydropower consistency environmental impact', 'answer': '**Consistency:**\\n- **Solar Power:** Inconsistent due to dependence on weather and daylight. Requires storage solutions (like batteries) for consistent supply.\\n- **Hydropower:** Highly reliable and consistent, as it can generate power continuously as long as water flow is maintained.\\n\\n**Environmental Impact:**\\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing PV panels involves resource extraction and energy use. Land use can also impact ecosystems.\\n- **Hydropower:** Large dams can significantly harm ecosystems, disrupt aquatic life, and displace communities. Run-of-river systems are less disruptive but still have some environmental impact.\\n\\nIn summary, hydropower is more consistent but has greater environmental impact, especially with large dams, while solar power is less consistent but generally cleaner, though it has its own environmental considerations.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7656936483985746), 'avg_score': np.float64(0.8885645494661915), 'time_sec': 9.473888397216797}\n",
            "{'chunk_size': 250, 'overlap': 30, 'top_k': 5, 'strategy': 'Rerank RAG (Simulated)', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': None, 'answer': '**Consistency:**  \\n- **Solar Power:** Inconsistent due to dependence on weather and daylight; requires storage (e.g., batteries) for reliable supply.  \\n- **Hydropower:** Highly reliable and consistent, as it can generate power continuously, especially with large dams.  \\n\\n**Environmental Impact:**  \\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing panels involves resource use and potential waste.  \\n- **Hydropower:** Large dams can significantly harm ecosystems, disrupt fish migration, and displace communities, though run-of-river systems are less disruptive.  \\n\\nIn summary, hydropower is more consistent but has greater environmental impacts, while solar power is cleaner but less consistent without storage.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7695743052498129), 'avg_score': np.float64(0.8898581017499376), 'time_sec': 8.33577299118042}\n",
            "{'chunk_size': 250, 'overlap': 50, 'top_k': 3, 'strategy': 'Simple RAG', 'retrieved_indices': [2, 0, 3], 'rewritten_query': None, 'answer': '**Consistency:**  \\n- **Hydropower** is highly reliable and provides consistent, large-scale power, especially when using dams. It is not dependent on weather conditions and can operate 24/7.  \\n- **Solar power** is less consistent as it varies with weather and time of day. It requires energy storage (e.g., batteries) to provide consistent power.  \\n\\n**Environmental Impact:**  \\n- **Hydropower** can have significant environmental impacts, including ecosystem disruption and community displacement, particularly with large dams. Run-of-river systems are less disruptive but still affect local ecosystems.  \\n- **Solar power** is cleaner with minimal environmental impact during operation, though manufacturing and disposal of panels can have ecological consequences. It does not disrupt ecosystems or displace communities.  \\n\\nIn summary, hydropower is more consistent but has greater environmental impact, while solar power is less consistent but generally more environmentally friendly.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7863330685934931), 'avg_score': np.float64(0.895444356197831), 'time_sec': 11.45156192779541}\n",
            "{'chunk_size': 250, 'overlap': 50, 'top_k': 3, 'strategy': 'Query Rewrite RAG', 'retrieved_indices': [2, 0, 3], 'rewritten_query': 'solar power consistency environmental impact, hydropower consistency environmental impact, comparison', 'answer': '**Consistency:**  \\n- **Hydropower** is highly reliable and provides consistent, large-scale power, especially with dams that can store water and regulate flow.  \\n- **Solar power** is less consistent as it depends on weather and daylight, requiring storage solutions like batteries for continuous supply.  \\n\\n**Environmental Impact:**  \\n- **Hydropower** can significantly harm ecosystems and displace communities, particularly with large dams, though run-of-river systems are less disruptive.  \\n- **Solar power** is cleaner with minimal environmental impact during operation, though manufacturing and disposal of panels can have ecological consequences.  \\n\\nIn summary, hydropower is more consistent but has greater environmental impacts, while solar power is less consistent but generally cleaner.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7699037860833384), 'avg_score': np.float64(0.8899679286944462), 'time_sec': 9.132622241973877}\n",
            "{'chunk_size': 250, 'overlap': 50, 'top_k': 3, 'strategy': 'Rerank RAG (Simulated)', 'retrieved_indices': [2, 0, 3], 'rewritten_query': None, 'answer': '**Consistency:**  \\n- **Hydropower** is highly reliable and provides consistent, large-scale power, as it is not dependent on weather or time of day.  \\n- **Solar power** is less consistent, as it varies with weather conditions and daylight availability. Storage solutions like batteries are essential to improve its reliability.  \\n\\n**Environmental Impact:**  \\n- **Hydropower** can have significant environmental impacts, including ecosystem disruption and community displacement, especially with large dams. Run-of-river systems are less disruptive but still affect local environments.  \\n- **Solar power** is cleaner with minimal environmental impact during operation, though manufacturing and disposal of panels can have ecological consequences.  \\n\\nIn summary, hydropower is more consistent but has greater environmental impacts, while solar power is less consistent but generally cleaner.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7747010903543686), 'avg_score': np.float64(0.8915670301181229), 'time_sec': 9.30941891670227}\n",
            "{'chunk_size': 250, 'overlap': 50, 'top_k': 5, 'strategy': 'Simple RAG', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': None, 'answer': '**Consistency:**\\n- **Solar Power:** Inconsistent due to dependence on weather and time of day. Requires storage solutions (e.g., batteries) for consistent power supply.\\n- **Hydropower:** Highly reliable and consistent, as it can generate power continuously, especially with large-scale dams.\\n\\n**Environmental Impact:**\\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing PV panels involves resource extraction and potential pollution. Land use can also impact ecosystems.\\n- **Hydropower:** Large dams significantly disrupt ecosystems, alter water flow, and displace communities. Run-of-river systems are less disruptive but still impact local habitats.\\n\\nIn summary, hydropower offers more consistent energy but has greater environmental impacts, particularly with large dams. Solar power is cleaner but less consistent, requiring storage for reliability.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7742312145265198), 'avg_score': np.float64(0.8914104048421733), 'time_sec': 10.07372260093689}\n",
            "{'chunk_size': 250, 'overlap': 50, 'top_k': 5, 'strategy': 'Query Rewrite RAG', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': 'solar power consistency environmental impact vs hydropower consistency environmental impact', 'answer': '**Consistency:**  \\n- **Solar Power:** Inconsistent due to dependence on weather and daylight. Requires storage solutions (e.g., batteries) for reliable power.  \\n- **Hydropower:** Highly reliable and consistent, as it can generate power continuously, especially with large dams that store water.  \\n\\n**Environmental Impact:**  \\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing panels involves resource use and potential waste. Land use for large installations can impact ecosystems.  \\n- **Hydropower:** Large dams significantly disrupt ecosystems, alter water flow, and displace communities. Run-of-river systems are less harmful but still impact local habitats.  \\n\\nIn summary, hydropower is more consistent but has greater environmental disruption, while solar power is cleaner but less consistent without storage.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7689425194609044), 'avg_score': np.float64(0.8896475064869681), 'time_sec': 11.73202395439148}\n",
            "{'chunk_size': 250, 'overlap': 50, 'top_k': 5, 'strategy': 'Rerank RAG (Simulated)', 'retrieved_indices': [2, 0, 3, 1, 4], 'rewritten_query': None, 'answer': '**Consistency:**\\n- **Solar Power:** Inconsistent due to dependence on weather and time of day. Requires storage solutions like batteries for consistent supply.\\n- **Hydropower:** Highly reliable and consistent, as it can generate power continuously as long as water flow is maintained.\\n\\n**Environmental Impact:**\\n- **Solar Power:** Clean with minimal emissions during operation, but manufacturing PV panels involves resource extraction and energy use. Large-scale installations can impact land use.\\n- **Hydropower:** Large dams can significantly harm ecosystems, disrupt aquatic life, and displace communities. Run-of-river systems are less disruptive but still impact local environments.\\n\\nIn summary, hydropower offers more consistent energy but has greater environmental impacts, especially with large dams. Solar power is cleaner but less consistent, requiring storage for reliability.', 'faithfulness': 0.9, 'relevancy': 1.0, 'similarity_score': np.float64(0.7681140997418485), 'avg_score': np.float64(0.8893713665806162), 'time_sec': 8.957494974136353}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('simple RAG: ',all_results[0]['answer'])\n",
        "print('Re-write query: ', all_results[1]['answer'])\n",
        "print('Rerank RAG (Simulated): ', all_results[2]['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l9ez4ckxIhc",
        "outputId": "329ee8d3-152c-4bc6-fa85-f1e8dcb55c2e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simple RAG:  **Consistency:**\n",
            "- **Hydropower** is highly reliable and provides consistent, large-scale power, as it is not dependent on weather conditions once the dam is operational.\n",
            "- **Solar power** is less consistent due to its dependence on sunlight, which varies with weather and time of day. Storage solutions like batteries are essential to mitigate this variability.\n",
            "\n",
            "**Environmental Impact:**\n",
            "- **Hydropower** has significant environmental impacts, including ecosystem disruption and community displacement, especially with large dams. Run-of-river systems are less disruptive but still affect local ecosystems.\n",
            "- **Solar power** is cleaner with minimal environmental impact during operation, though the production and disposal of PV panels can have environmental consequences. It does not disrupt ecosystems or displace communities.\n",
            "Re-write query:  **Consistency:**\n",
            "- **Hydropower** is highly consistent and reliable, providing large-scale power 24/7, as it is not dependent on weather or time of day.\n",
            "- **Solar power** is less consistent, as it varies with weather conditions and time of day (sunlight availability). Storage solutions like batteries are essential to improve its reliability.\n",
            "\n",
            "**Environmental Impact:**\n",
            "- **Hydropower** has significant environmental impacts, particularly from large dams, which can harm ecosystems, disrupt fish migration, and displace communities. Run-of-river systems are less disruptive but still have some ecological effects.\n",
            "- **Solar power** is cleaner with minimal environmental impact during operation. However, the production and disposal of PV panels can have environmental consequences, and large solar farms may affect land use.\n",
            "\n",
            "In summary, hydropower offers more consistent energy but with greater environmental disruption, while solar power is cleaner but less consistent without storage solutions.\n",
            "Rerank RAG (Simulated):  **Consistency:**  \n",
            "- **Hydropower** is highly reliable and provides consistent, large-scale power, especially with dams that can store water and regulate flow.  \n",
            "- **Solar power** is less consistent as it varies with weather and time of day, requiring storage solutions like batteries for more reliable output.  \n",
            "\n",
            "**Environmental Impact:**  \n",
            "- **Hydropower** can have significant environmental impacts, including ecosystem disruption and community displacement, particularly with large dams. Run-of-river systems are less disruptive but still affect local habitats.  \n",
            "- **Solar power** is cleaner with minimal environmental impact during operation, though manufacturing and disposal of panels can have ecological consequences.  \n",
            "\n",
            "In summary, hydropower is more consistent but has greater environmental impacts, while solar power is less consistent but generally cleaner.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_simulated_rerank=False\n",
        "query_to_use=\"Compare the consistency and environmental impact of solar power versus hydropower\"\n",
        "k_retrieve=3\n",
        "k_for_search = k_retrieve * RERANK_RETRIEVAL_MULTIPLIER if use_simulated_rerank else k_retrieve\n",
        "\n",
        "query_embedding_response = client.embeddings.create(model=NEBIUS_EMBEDDING_MODEL, input=[query_to_use])\n",
        "query_vector = np.array([query_embedding_response.data[0].embedding]).astype('float32')\n",
        "\n",
        "actual_k = min(k_for_search, current_index.ntotal)\n",
        "if actual_k == 0:\n",
        "  raise ValueError(\"Index is empty or k_for_search is zero.\")\n",
        "\n",
        "distances, indices = current_index.search(query_vector, actual_k)\n",
        "valid_indices = indices[0][indices[0] != -1].tolist()\n",
        "final_indices = valid_indices[:k_retrieve] if use_simulated_rerank else valid_indices\n",
        "\n",
        "retrieved_chunks = [current_chunks[i] for i in final_indices]\n",
        "\n",
        "\n",
        "# --- Generation ---\n",
        "context_str = \"\\n\\n\".join(retrieved_chunks)\n",
        "sys_prompt_gen = \"You are a helpful AI assistant. Answer the user's query based strictly on the provided context. If the context doesn't contain the answer, state that clearly. Be concise.\"\n",
        "user_prompt_gen = f\"Context:\\n------\\n{context_str}\\n------\\n\\nQuery: {test_query}\\n\\nAnswer:\"\n",
        "\n",
        "gen_response = client.chat.completions.create(\n",
        "    model=NEBIUS_GENERATION_MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": sys_prompt_gen},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_gen}\n",
        "    ],\n",
        "    temperature=GENERATION_TEMPERATURE,\n",
        "    max_tokens=GENERATION_MAX_TOKENS,\n",
        "    top_p=GENERATION_TOP_P\n",
        ")\n",
        "\n",
        "generated_answer = gen_response.choices[0].message.content.strip()\n",
        "eval_params = {'model': NEBIUS_EVALUATION_MODEL, 'temperature': 0.0, 'max_tokens': 10}\n",
        "prompt_f = FAITHFULNESS_PROMPT.format(question=test_query, response=generated_answer, true_answer=true_answer_for_query)\n",
        "resp_f = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": prompt_f}], **eval_params)"
      ],
      "metadata": {
        "id": "B9YoXXbvbIr4"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp_f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz2wF0IMcipr",
        "outputId": "4967b831-4625-44de-e8a2-a0115961b35e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-940aeae8d5d64fd48cdf294f46dcbace', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='0.9', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None), stop_reason=None)], created=1746347889, model='deepseek-ai/DeepSeek-V3', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=4, prompt_tokens=439, total_tokens=443, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_and_evaluate(strategy_name, query_to_use, k_retrieve, true_answer_for_query, use_simulated_rerank=False):\n",
        "    run_start_time = time.time()\n",
        "\n",
        "    result = {\n",
        "        'chunk_size': chunk_size,\n",
        "        'overlap': chunk_overlap,\n",
        "        'top_k': k_retrieve,\n",
        "        'strategy': strategy_name,\n",
        "        'retrieved_indices': [],\n",
        "        'rewritten_query': None,\n",
        "        'answer': 'Error: Execution Failed',\n",
        "        'faithfulness': 0.0,\n",
        "        'relevancy': 0.0,\n",
        "        'similarity_score': 0.0,\n",
        "        'avg_score': 0.0,\n",
        "        'time_sec': 0.0\n",
        "    }\n",
        "\n",
        "    if strategy_name == \"Query Rewrite RAG\":\n",
        "        result['rewritten_query'] = query_to_use\n",
        "\n",
        "    try:\n",
        "        # --- Retrieval ---\n",
        "        k_for_search = k_retrieve * RERANK_RETRIEVAL_MULTIPLIER if use_simulated_rerank else k_retrieve\n",
        "\n",
        "        query_embedding_response = client.embeddings.create(model=NEBIUS_EMBEDDING_MODEL, input=[query_to_use])\n",
        "        query_vector = np.array([query_embedding_response.data[0].embedding]).astype('float32')\n",
        "\n",
        "        actual_k = min(k_for_search, current_index.ntotal)\n",
        "        if actual_k == 0:\n",
        "            raise ValueError(\"Index is empty or k_for_search is zero.\")\n",
        "\n",
        "        distances, indices = current_index.search(query_vector, actual_k)\n",
        "        valid_indices = indices[0][indices[0] != -1].tolist()\n",
        "        final_indices = valid_indices[:k_retrieve] if use_simulated_rerank else valid_indices\n",
        "\n",
        "        result['retrieved_indices'] = final_indices\n",
        "        retrieved_chunks = [current_chunks[i] for i in final_indices]\n",
        "\n",
        "        if not retrieved_chunks:\n",
        "            result['answer'] = \"No relevant context found in the documents based on the query.\"\n",
        "        else:\n",
        "            # --- Generation ---\n",
        "            context_str = \"\\n\\n\".join(retrieved_chunks)\n",
        "            sys_prompt_gen = \"You are a helpful AI assistant. Answer the user's query based strictly on the provided context. If the context doesn't contain the answer, state that clearly. Be concise.\"\n",
        "            user_prompt_gen = f\"Context:\\n------\\n{context_str}\\n------\\n\\nQuery: {test_query}\\n\\nAnswer:\"\n",
        "\n",
        "            gen_response = client.chat.completions.create(\n",
        "                model=NEBIUS_GENERATION_MODEL,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": sys_prompt_gen},\n",
        "                    {\"role\": \"user\", \"content\": user_prompt_gen}\n",
        "                ],\n",
        "                temperature=GENERATION_TEMPERATURE,\n",
        "                max_tokens=GENERATION_MAX_TOKENS,\n",
        "                top_p=GENERATION_TOP_P\n",
        "            )\n",
        "\n",
        "            generated_answer = gen_response.choices[0].message.content.strip()\n",
        "            result['answer'] = generated_answer\n",
        "\n",
        "            # --- Evaluation ---\n",
        "            eval_params = {'model': NEBIUS_EVALUATION_MODEL, 'temperature': 0.0, 'max_tokens': 10}\n",
        "\n",
        "            try:\n",
        "                prompt_f = FAITHFULNESS_PROMPT.format(question=test_query, response=generated_answer, true_answer=true_answer_for_query)\n",
        "                resp_f = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": prompt_f}], **eval_params)\n",
        "                result['faithfulness'] = max(0.0, min(1.0, float(resp_f.choices[0].message.content.strip())))\n",
        "            except Exception as e:\n",
        "                print(f\"      Warning: Faithfulness eval failed: {e}\")\n",
        "                result['faithfulness'] = 0.0\n",
        "\n",
        "            try:\n",
        "                prompt_r = RELEVANCY_PROMPT.format(question=test_query, response=generated_answer)\n",
        "                resp_r = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": prompt_r}], **eval_params)\n",
        "                result['relevancy'] = max(0.0, min(1.0, float(resp_r.choices[0].message.content.strip())))\n",
        "            except Exception as e:\n",
        "                print(f\"      Warning: Relevancy eval failed: {e}\")\n",
        "                result['relevancy'] = 0.0\n",
        "\n",
        "            result['similarity_score'] = calculate_cosine_similarity(\n",
        "                generated_answer, true_answer_for_query, client, NEBIUS_EMBEDDING_MODEL\n",
        "            )\n",
        "            result['avg_score'] = (result['faithfulness'] + result['relevancy'] + result['similarity_score']) / 3.0\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"ERROR during {strategy_name} (C={chunk_size}, O={chunk_overlap}, K={k_retrieve}): {str(e)[:200]}...\"\n",
        "        print(f\"    {error_message}\")\n",
        "        result['answer'] = error_message\n",
        "\n",
        "    result['time_sec'] = time.time() - run_start_time\n",
        "    print(f\"    Finished: {strategy_name} (C={chunk_size}, O={chunk_overlap}, K={k_retrieve}). AvgScore={result['avg_score']:.2f}, Time={result['time_sec']:.2f}s\")\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "wpIRrKP5_CcE"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_query = \"Compare the consistency and environmental impact of solar power versus hydropower.\"\n",
        "true_answer_for_query = \"Solar power's consistency varies with weather and time of day, requiring storage like batteries. Hydropower is generally reliable, but large dams have significant environmental impacts on ecosystems and communities, unlike solar power's primary impact being land use for panels.\"\n",
        "\n",
        "print(f\"Loaded {len(corpus_texts)} documents into our corpus.\")\n",
        "print(f\"Test Query: '{test_query}'\")\n",
        "print(f\"Reference (True) Answer for evaluation: '{true_answer_for_query}'\")\n",
        "print(\"Input data is ready.\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "top_k=3\n",
        "result_simple = run_and_evaluate(\"Simple RAG\", test_query,top_k, true_answer_for_query )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZWBgf_Ksb80",
        "outputId": "7e606224-da03-4f2f-a2d2-1588ea1009c2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 5 documents into our corpus.\n",
            "Test Query: 'Compare the consistency and environmental impact of solar power versus hydropower.'\n",
            "Reference (True) Answer for evaluation: 'Solar power's consistency varies with weather and time of day, requiring storage like batteries. Hydropower is generally reliable, but large dams have significant environmental impacts on ecosystems and communities, unlike solar power's primary impact being land use for panels.'\n",
            "Input data is ready.\n",
            "-------------------------\n",
            "    Finished: Simple RAG (C=250, O=50, K=3). AvgScore=0.89, Time=13.30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys_prompt_rw = \"You are an expert query optimizer. Rewrite the user's query to be ideal for vector database retrieval. Focus on key entities, concepts, and relationships. Remove conversational fluff. Output ONLY the rewritten query text.\"\n",
        "user_prompt_rw = f\"Original Query: {test_query}\\n\\nRewritten Query:\"\n",
        "\n",
        "# Call the LLM to rewrite the query\n",
        "resp_rw = client.chat.completions.create(\n",
        "    model=NEBIUS_GENERATION_MODEL, # Can use the generation model for this task too\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": sys_prompt_rw},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_rw}\n",
        "    ],\n",
        "    temperature=0.1, # Low temp for focused rewrite\n",
        "    max_tokens=100,\n",
        "    top_p=0.9\n",
        ")\n",
        "# Clean up the LLM's response to get just the query text\n",
        "candidate_q = resp_rw.choices[0].message.content.strip()\n",
        "# Remove potential prefixes like \"Rewritten Query:\" or \"Query:\"\n",
        "candidate_q = re.sub(r'^(rewritten query:|query:)\\s*', '', candidate_q, flags=re.IGNORECASE).strip('\"')\n",
        "\n",
        "# Use the rewritten query only if it's reasonably different and not too short\n",
        "if candidate_q and len(candidate_q) > 5 and candidate_q.lower() != test_query.lower():\n",
        "    rewritten_q = candidate_q"
      ],
      "metadata": {
        "id": "Neob6vG9Lz8m"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_rewrite = run_and_evaluate(\"Query Rewrite RAG\", rewritten_q, top_k,true_answer_for_query)\n",
        "all_results.append(result_rewrite)"
      ],
      "metadata": {
        "id": "Ei5KVEuNskEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09bb5822-c096-4a84-a2aa-3585e869d25b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Finished: Query Rewrite RAG (C=250, O=50, K=3). AvgScore=0.89, Time=8.25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_rerank = run_and_evaluate(\"Rerank RAG (Simulated)\", test_query, top_k, true_answer_for_query)\n",
        "all_results.append(result_rerank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A446aycgL4lc",
        "outputId": "779bacae-5a96-4c8d-a170-f1f5c34c5097"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Finished: Rerank RAG (Simulated) (C=250, O=50, K=3). AvgScore=0.89, Time=10.28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0oy2aB44P_Nf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}